{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Racing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if needed !pip install swig\n",
    "# !pip install 'gymnasium[box2d]'\n",
    "# !pip install 'stable-baselines3[extra]'\n",
    "# !pip install 'syne-tune[basic]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from syne_tune import Tuner\n",
    "from syne_tune.backend import PythonBackend\n",
    "from syne_tune.experiments import load_experiment\n",
    "from syne_tune.config_space import loguniform, uniform, choice\n",
    "from syne_tune.optimizer.baselines import ASHA\n",
    "from syne_tune.stopping_criterion import StoppingCriterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter search space\n",
    "config_space = {\n",
    "    \"learning_rate\": loguniform(1e-8, 0.1),\n",
    "    \"tau\":  loguniform(1e-8, 1),\n",
    "    \"gamma\": uniform(0.9, 0.999),    \n",
    "    \"steps\": 50 # TODO increase\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tuning function\n",
    "def train_hpo_model(learning_rate: float, tau: float, gamma: float, steps: int):\n",
    "    # Worker imports\n",
    "    import numpy as np\n",
    "    from stable_baselines3.common.env_util import make_vec_env\n",
    "    from stable_baselines3.common.evaluation import evaluate_policy\n",
    "    from stable_baselines3.common.callbacks import BaseCallback\n",
    "    from stable_baselines3.common.noise import NormalActionNoise\n",
    "    from stable_baselines3 import TD3\n",
    "    \n",
    "    from syne_tune import Reporter\n",
    "\n",
    "    # Create the vectorized environment\n",
    "    env_id = \"CarRacing-v2\"\n",
    "    vec_env = make_vec_env(env_id, n_envs=4)\n",
    "    \n",
    "    # Initialize the PPO agent with the given hyperparameters\n",
    "    n_actions = vec_env.action_space.shape[-1]\n",
    "    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))  \n",
    "    model = TD3(\"CnnPolicy\", vec_env,  \n",
    "                action_noise=action_noise,\n",
    "                learning_rate=learning_rate,\n",
    "                tau=tau,\n",
    "                gamma=gamma,\n",
    "                batch_size=32,\n",
    "                verbose=1)\n",
    "\n",
    "    report = Reporter()\n",
    "    class WorkerCallback(BaseCallback):\n",
    "        def _on_step(self) -> bool:\n",
    "            # Log the mean reward\n",
    "            mean_reward = sum(self.locals[\"rewards\"]) / len(self.locals[\"rewards\"])\n",
    "            step = self.locals[\"num_collected_steps\"]\n",
    "            report(step=step, mean_reward=mean_reward, n_step=step + 1)\n",
    "            return True \n",
    "    \n",
    "    # Train the agent\n",
    "    worker_callback = WorkerCallback()\n",
    "    model.learn(total_timesteps=steps, callback=worker_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"mean_reward\"\n",
    "scheduler = ASHA(\n",
    "    config_space,\n",
    "    metric=metric,\n",
    "    max_resource_attr=\"steps\",\n",
    "    resource_attr=\"n_step\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "trial_backend = PythonBackend(\n",
    "    tune_function=train_hpo_model, config_space=config_space\n",
    ")\n",
    "stop_criterion = StoppingCriterion(\n",
    "    max_wallclock_time=30, \n",
    "    max_num_trials_completed=1000\n",
    ")\n",
    "tuner = Tuner(\n",
    "    trial_backend=trial_backend,\n",
    "    scheduler=scheduler,\n",
    "    stop_criterion=stop_criterion,\n",
    "    n_workers=1,\n",
    "    save_tuner=False,\n",
    "    wait_trial_completion_when_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:syne_tune.backend.local_backend:num_gpus_per_trial = 1 is too large, reducing to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Resource summary (last result is reported):\n",
      " trial_id    status  iter  learning_rate          tau    gamma  steps  step  mean_reward  n_step  worker-time\n",
      "        0 Completed    13   3.162278e-05 1.000000e-04 0.949500     50     1         -0.1       2     0.354981\n",
      "        1 Completed    13   2.842344e-03 1.168070e-01 0.992298     50     1         -0.1       2     0.350097\n",
      "        2 Completed    13   3.567599e-02 2.212191e-03 0.954412     50     1         -0.1       2     0.349499\n",
      "        3 Completed    13   9.283290e-06 4.610815e-04 0.980848     50     1         -0.1       2     0.362427\n",
      "        4 Completed    13   1.781584e-08 1.169409e-03 0.923024     50     1         -0.1       2     0.369614\n",
      "        5 Completed    13   1.568845e-07 3.019649e-07 0.934429     50     1         -0.1       2     0.341538\n",
      "0 trials running, 6 finished (6 until the end), 30.22s wallclock-time\n",
      "\n",
      "mean_reward: best -0.10000000149011612 for trial-id 0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Start hyperparameter tuning\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 1,\n",
       " 'mean_reward': -0.1000000014901161,\n",
       " 'n_step': 2,\n",
       " 'trial_id': 0,\n",
       " 'config_learning_rate': 3.162277660168375e-05,\n",
       " 'config_tau': 9.999999999999992e-05,\n",
       " 'config_gamma': 0.9495,\n",
       " 'config_steps': 50}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results\n",
    "tuner_path = tuner.tuner_path\n",
    "tuning_experiment = load_experiment(tuner_path)\n",
    "# tuning_experiment.results\n",
    "tuning_experiment.best_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
