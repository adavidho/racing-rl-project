{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Racing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T09:21:18.664476Z",
     "iopub.status.busy": "2024-07-07T09:21:18.664229Z",
     "iopub.status.idle": "2024-07-07T09:21:18.671510Z",
     "shell.execute_reply": "2024-07-07T09:21:18.670872Z"
    }
   },
   "outputs": [],
   "source": [
    "# # General\n",
    "import platform\n",
    "assert platform.python_version() == \"3.10.14\"\n",
    "# !pip install 'gymnasium[box2d]'\n",
    "# !pip install 'syne-tune[basic]'\n",
    "# !pip install 'stable-baselines3[extra]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T09:21:18.674389Z",
     "iopub.status.busy": "2024-07-07T09:21:18.674141Z",
     "iopub.status.idle": "2024-07-07T09:21:21.053869Z",
     "shell.execute_reply": "2024-07-07T09:21:21.053019Z"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from syne_tune import Tuner\n",
    "from syne_tune.backend import PythonBackend\n",
    "from syne_tune.experiments import load_experiment\n",
    "from syne_tune.config_space import loguniform, uniform, choice\n",
    "from syne_tune.optimizer.baselines import ASHA\n",
    "from syne_tune.stopping_criterion import StoppingCriterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T09:21:21.057708Z",
     "iopub.status.busy": "2024-07-07T09:21:21.057116Z",
     "iopub.status.idle": "2024-07-07T09:21:21.061101Z",
     "shell.execute_reply": "2024-07-07T09:21:21.060374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameter search space\n",
    "config_space = {\n",
    "    \"learning_rate\": loguniform(1e-8, 0.1),\n",
    "    \"tau\":  loguniform(1e-8, 1),\n",
    "    \"gamma\": uniform(0.9, 0.999),    \n",
    "    \"steps\": 1000000 # TODO increase\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T09:21:21.063966Z",
     "iopub.status.busy": "2024-07-07T09:21:21.063716Z",
     "iopub.status.idle": "2024-07-07T09:21:21.071160Z",
     "shell.execute_reply": "2024-07-07T09:21:21.070512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the tuning function\n",
    "def train_hpo_model(learning_rate: float, tau: float, gamma: float, steps: int):\n",
    "    # Worker imports\n",
    "    import gymnasium as gym\n",
    "    import numpy as np\n",
    "    from stable_baselines3.common.env_util import make_vec_env\n",
    "    from stable_baselines3.common.evaluation import evaluate_policy\n",
    "    from stable_baselines3.common.callbacks import BaseCallback\n",
    "    from stable_baselines3.common.noise import NormalActionNoise\n",
    "    from stable_baselines3 import TD3\n",
    "    \n",
    "    from syne_tune import Reporter\n",
    "    import torch\n",
    "    assert torch.cuda.is_available()\n",
    "    # Create the vectorized environment\n",
    "    env_id = \"CarRacing-v2\"\n",
    "    # vec_env = make_vec_env(env_id, n_envs=4) # TODO why didn't you use vec env? no muli processing\n",
    "    env = gym.make(env_id, domain_randomize=True)\n",
    "    \n",
    "    # Initialize the PPO agent with the given hyperparameters\n",
    "    n_actions = env.action_space.shape[-1]\n",
    "    # n_actions = vec_env.action_space.shape[-1]\n",
    "    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))  \n",
    "    model = TD3(\n",
    "        \"CnnPolicy\", \n",
    "        # vec_env,  \n",
    "        env,\n",
    "        action_noise=action_noise,\n",
    "        learning_rate=learning_rate,\n",
    "        tau=tau,\n",
    "        gamma=gamma,\n",
    "        batch_size=64, # Tested 32, 64 and finally 256 which failed after a few hours\n",
    "        verbose=1,\n",
    "        device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    report = Reporter()\n",
    "    class WorkerCallback(BaseCallback):\n",
    "        def _on_step(self) -> bool:\n",
    "            # Log the mean reward\n",
    "            mean_reward = sum(self.locals[\"rewards\"]) / len(self.locals[\"rewards\"])\n",
    "            step = self.locals[\"num_collected_steps\"]\n",
    "            report(step=step, mean_reward=mean_reward)\n",
    "            return True \n",
    "    \n",
    "    # Train the agent\n",
    "    worker_callback = WorkerCallback()\n",
    "    model.learn(total_timesteps=steps, callback=worker_callback, log_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T09:21:21.074014Z",
     "iopub.status.busy": "2024-07-07T09:21:21.073769Z",
     "iopub.status.idle": "2024-07-07T09:21:21.080629Z",
     "shell.execute_reply": "2024-07-07T09:21:21.079972Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = \"mean_reward\"\n",
    "scheduler = ASHA(\n",
    "    config_space,\n",
    "    metric=metric,\n",
    "    max_resource_attr=\"steps\",\n",
    "    resource_attr=\"step\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "trial_backend = PythonBackend(\n",
    "    tune_function=train_hpo_model, config_space=config_space, rotate_gpus=True\n",
    ")\n",
    "stop_criterion = StoppingCriterion(\n",
    "    max_wallclock_time=61200, # 2 hours, first we did 4 days, stuck (see below) to little time left so now only 1 day\n",
    ")\n",
    "tuner = Tuner(\n",
    "    trial_backend=trial_backend,\n",
    "    scheduler=scheduler,\n",
    "    stop_criterion=stop_criterion,\n",
    "    n_workers=8,\n",
    "    save_tuner=False,\n",
    "    wait_trial_completion_when_stopping=False, # Problem with termintation, waits until all running jobs are finished. May take a long time with 1M steps  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T09:21:21.083515Z",
     "iopub.status.busy": "2024-07-07T09:21:21.083264Z",
     "iopub.status.idle": "2024-07-07T09:26:25.450015Z",
     "shell.execute_reply": "2024-07-07T09:26:25.449143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start hyperparameter tuning\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T09:26:25.453518Z",
     "iopub.status.busy": "2024-07-07T09:26:25.453254Z",
     "iopub.status.idle": "2024-07-07T09:26:26.445451Z",
     "shell.execute_reply": "2024-07-07T09:26:26.444771Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "tuner_path = tuner.tuner_path\n",
    "tuning_experiment = load_experiment(tuner_path)\n",
    "tuning_experiment.results.to_csv(\"tuning_results.csv\")\n",
    "tuning_experiment.best_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
